import asyncio
import time
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from fastapi.responses import Response

from .models.schemas import (
    ChatRequest, ChatResponse, FeedbackRequest, FeedbackResponse,
    SystemMetrics, AgentMode
)
from .services.memory_service import EnhancedMemoryService
from .services.mcp_service import MCPService
from .services.feedback_service import EnhancedFeedbackService
from .services.agent_service import EnhancedAgentService
from .utils.config import config

# Prometheus ë©”íŠ¸ë¦­
REQUEST_COUNT = Counter('requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('request_duration_seconds', 'Request duration')
MEMORY_OPERATIONS = Counter('memory_operations_total', 'Memory operations', ['operation_type'])

# ê¸€ë¡œë²Œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
memory_service = None
mcp_service = None
feedback_service = None
agent_service = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    global memory_service, mcp_service, feedback_service, agent_service
    
    # ì‹œì‘ ì‹œ ì´ˆê¸°í™”
    logging.info("ğŸš€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
    
    memory_service = EnhancedMemoryService()
    await memory_service.initialize()
    logging.info("âœ… ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    mcp_service = MCPService()
    logging.info("âœ… MCP ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    feedback_service = EnhancedFeedbackService(memory_service)
    logging.info("âœ… í”¼ë“œë°± ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    agent_service = EnhancedAgentService(memory_service, mcp_service, feedback_service)
    logging.info("âœ… ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    logging.info("ğŸ‰ ëª¨ë“  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    logging.info("ğŸ›‘ ì„œë¹„ìŠ¤ ì¢…ë£Œ ì¤‘...")
    if memory_service.redis_client:
        await memory_service.redis_client.close()
    if memory_service.neo4j_driver:
        memory_service.neo4j_driver.close()
    logging.info("âœ… ì •ë¦¬ ì™„ë£Œ")

app = FastAPI(
    title="Enhanced Agentic AI PoC",
    description="MCP ë„êµ¬ ê¸°ë°˜ ì§€ëŠ¥í˜• ë©”ëª¨ë¦¬ì™€ í”¼ë“œë°± ë£¨í”„ë¥¼ ê°–ì¶˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ",
    version="2.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.middleware("http")
async def add_prometheus_metrics(request, call_next):
    """Prometheus ë©”íŠ¸ë¦­ ë¯¸ë“¤ì›¨ì–´"""
    start_time = time.time()
    
    response = await call_next(request)
    
    # ë©”íŠ¸ë¦­ ê¸°ë¡
    REQUEST_COUNT.labels(method=request.method, endpoint=request.url.path).inc()
    REQUEST_DURATION.observe(time.time() - start_time)
    
    return response

# === API ì—”ë“œí¬ì¸íŠ¸ ===

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """ë©”ì¸ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        start_time = time.time()
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ í¬ë¡œìŠ¤ ì—ì´ì „íŠ¸ í•™ìŠµ ì ìš©
        await feedback_service.process_immediate_feedback(FeedbackRequest(
            session_id=request.session_id,
            user_id=request.user_id,
            feedback_type="preference_sync",
            content="í¬ë¡œìŠ¤ ì—ì´ì „íŠ¸ ì„ í˜¸ë„ ë™ê¸°í™”"
        ))
        
        # ì±„íŒ… ì²˜ë¦¬
        response = await agent_service.process_chat(
            message=request.message,
            user_id=request.user_id,
            session_id=request.session_id,
            mode=request.mode,
            context=request.context
        )
        
        MEMORY_OPERATIONS.labels(operation_type="chat_processing").inc()
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.post("/feedback", response_model=FeedbackResponse)
async def feedback_endpoint(request: FeedbackRequest):
    """ì¦‰ì‹œ í”¼ë“œë°± ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        response = await feedback_service.process_immediate_feedback(request)
        MEMORY_OPERATIONS.labels(operation_type="feedback_processing").inc()
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.get("/memory/stats")
async def memory_stats_endpoint():
    """ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ í†µê³„"""
    try:
        stats = await memory_service.get_memory_statistics()
        MEMORY_OPERATIONS.labels(operation_type="stats_query").inc()
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/mcp/tools/performance")
async def mcp_performance_endpoint():
    """MCP ë„êµ¬ ì„±ëŠ¥ í†µê³„"""
    try:
        stats = mcp_service.get_all_performance_stats()
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"MCP ì„±ëŠ¥ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/feedback/optimization-history")
async def optimization_history_endpoint():
    """ìµœì í™” ì´ë ¥ ì¡°íšŒ"""
    try:
        history = await feedback_service.get_optimization_history()