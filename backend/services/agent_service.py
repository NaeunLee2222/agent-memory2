import asyncio
import time
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from openai import OpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from ..services.memory_service import EnhancedMemoryService
from ..services.mcp_service import MCPService
from ..services.feedback_service import EnhancedFeedbackService
from ..models.schemas import (
    AgentMode,
    ChatResponse,
    WorkflowStep,
    WorkflowPattern,
    MCPToolCall,
    MCPToolType,
    MemoryType,
    EpisodicMemory,
)
from ..utils.config import config


class EnhancedAgentService:
    def __init__(
        self,
        memory_service: EnhancedMemoryService,
        mcp_service: MCPService,
        feedback_service: EnhancedFeedbackService,
    ):
        self.memory_service = memory_service
        self.mcp_service = mcp_service
        self.feedback_service = feedback_service
        self.openai_client = OpenAI(api_key=config.OPENAI_API_KEY)
        self.checkpointer = MemorySaver()

        # ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ì €ì¥ì†Œ
        self.learned_patterns = {}

    async def process_chat(
        self,
        message: str,
        user_id: str,
        session_id: str,
        mode: AgentMode,
        context: Dict[str, Any] = None,
    ) -> ChatResponse:
        """ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬"""
        start_time = time.time()
        context = context or {}

        # 1. ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        memories, memory_retrieval_time = (
            await self.memory_service.retrieve_relevant_memories(
                user_id=user_id,
                query=message,
                memory_types=[
                    MemoryType.PROCEDURAL,
                    MemoryType.EPISODIC,
                    MemoryType.SEMANTIC,
                ],
                limit=3,
            )
        )

        # 2. ì‚¬ìš©ì ì„ í˜¸ë„ ì ìš©
        user_preferences = await self.feedback_service.get_user_preferences(user_id)

        # 3. ëª¨ë“œë³„ ì²˜ë¦¬
        if mode == AgentMode.FLOW:
            workflow_result = await self._process_flow_mode(
                message, user_id, session_id, memories, user_preferences, context
            )
        else:
            workflow_result = await self._process_basic_mode(
                message, user_id, session_id, memories, user_preferences, context
            )

        # 4. ì‘ë‹µ ìƒì„±
        response_text = await self._generate_response(
            message, workflow_result, user_preferences
        )

        # 5. ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ì— ìƒí˜¸ì‘ìš© ì €ì¥
        episode = EpisodicMemory(
            episode_id=f"{session_id}_{int(time.time() * 1000)}",
            user_id=user_id,
            session_id=session_id,
            timestamp=datetime.now(),
            interaction_type="chat_interaction",
            context={
                "message": message,
                "mode": mode,
                "response": response_text,
                "tools_used": [
                    result.tool_type for result in workflow_result["tools_used"]
                ],
                "processing_time": time.time() - start_time,
            },
            workflow_executed=workflow_result.get("workflow_pattern"),
            lessons_learned=workflow_result.get("lessons_learned", []),
        )

        await self.memory_service.store_episodic_memory(episode)

        # 6. ì„±ëŠ¥ í”¼ë“œë°± ì²˜ë¦¬
        for tool_result in workflow_result["tools_used"]:
            await self.feedback_service.process_performance_feedback(
                tool_type=tool_result.tool_type,
                execution_time=tool_result.execution_time,
                success=tool_result.success,
                error_type=tool_result.error,
            )

        total_processing_time = time.time() - start_time

        return ChatResponse(
            response=response_text,
            session_id=session_id,
            workflow_executed=workflow_result.get("workflow_pattern"),
            memory_used={
                MemoryType.WORKING: [f"ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸: {len(context)} í•­ëª©"],
                MemoryType.EPISODIC: [
                    m["content"][:100] for m in memories[MemoryType.EPISODIC][:2]
                ],
                MemoryType.SEMANTIC: [
                    m["content"][:100] for m in memories[MemoryType.SEMANTIC][:2]
                ],
                MemoryType.PROCEDURAL: [
                    m["content"][:100] for m in memories[MemoryType.PROCEDURAL][:2]
                ],
            },
            processing_time=total_processing_time,
            tools_used=workflow_result["tools_used"],
            confidence_score=workflow_result.get("confidence_score", 0.8),
            optimization_applied=workflow_result.get("optimizations", []),
        )

    async def _process_flow_mode(
        self,
        message: str,
        user_id: str,
        session_id: str,
        memories: Dict[MemoryType, List],
        user_preferences: Dict,
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """í”Œë¡œìš° ëª¨ë“œ ì²˜ë¦¬ - êµ¬ì¡°í™”ëœ Step-Action-Tool ì‹¤í–‰"""

        # 1. ìœ ì‚¬í•œ ì ˆì°¨ íŒ¨í„´ ê²€ìƒ‰
        similar_procedures, _ = await self.memory_service.retrieve_similar_procedures(
            message, user_id, limit=3
        )

        # 2. ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ê³„íš ë˜ëŠ” ê¸°ì¡´ íŒ¨í„´ ì¬ì‚¬ìš©
        if similar_procedures and similar_procedures[0].get("relevance_score", 0) > 0.8:
            # ê¸°ì¡´ íŒ¨í„´ ì¬ì‚¬ìš©
            workflow_pattern = await self._reuse_workflow_pattern(
                similar_procedures[0], context
            )
            optimization_note = ["ê¸°ì¡´ ì„±ê³µ íŒ¨í„´ ì¬ì‚¬ìš©"]
        else:
            # ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ê³„íš
            workflow_pattern = await self._plan_new_workflow(
                message, memories, user_preferences, context
            )
            optimization_note = ["ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ìƒì„±"]

        # 3. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        execution_results = await self._execute_workflow(workflow_pattern)

        # 4. ì„±ê³µí•œ íŒ¨í„´ì„ ì ˆì°¨ ë©”ëª¨ë¦¬ì— ì €ì¥
        if all(result.success for result in execution_results):
            workflow_pattern.success_rate = 1.0
            workflow_pattern.usage_count = workflow_pattern.usage_count + 1
            await self.memory_service.store_procedural_memory(workflow_pattern, user_id)
            optimization_note.append("ì„±ê³µ íŒ¨í„´ í•™ìŠµ ì™„ë£Œ")

        return {
            "workflow_pattern": workflow_pattern,
            "tools_used": execution_results,
            "confidence_score": (
                0.9 if all(r.success for r in execution_results) else 0.6
            ),
            "optimizations": optimization_note,
            "lessons_learned": self._extract_lessons_from_execution(execution_results),
        }

    async def _process_basic_mode(
        self,
        message: str,
        user_id: str,
        session_id: str,
        memories: Dict[MemoryType, List],
        user_preferences: Dict,
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ê¸°ë³¸ ëª¨ë“œ ì²˜ë¦¬ - ììœ¨ì  ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰"""

        # 1. ìì—°ì–´ ì˜ë„ ë¶„ì„
        intent_analysis = await self._analyze_user_intent(
            message, memories, user_preferences
        )

        # 2. ìµœì  ë„êµ¬ ì¡°í•© ì¶”ì²œ
        suggested_tools = self.mcp_service.suggest_optimal_tool_combination(message)

        # 3. ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë„êµ¬ ì„ íƒ ê°œì„ 
        if memories[MemoryType.EPISODIC]:
            refined_tools = await self._refine_tools_from_episodes(
                suggested_tools, memories[MemoryType.EPISODIC]
            )
        else:
            refined_tools = suggested_tools

        # 4. ë„êµ¬ ì‹¤í–‰
        tool_calls = []
        for tool_type in refined_tools[:3]:  # ìµœëŒ€ 3ê°œ ë„êµ¬
            tool_call = MCPToolCall(
                tool_type=tool_type,
                parameters=self._generate_tool_parameters(
                    tool_type, message, intent_analysis
                ),
                context=context,
            )
            tool_calls.append(tool_call)

        execution_results = await self.mcp_service.execute_workflow(tool_calls)

        # 5. ì‹¤í–‰ ê²°ê³¼ ê¸°ë°˜ í•™ìŠµ
        lessons_learned = []
        if execution_results:
            success_rate = sum(1 for r in execution_results if r.success) / len(
                execution_results
            )
            if success_rate > 0.8:
                lessons_learned.append(
                    f"ë„êµ¬ ì¡°í•© {[r.tool_type for r in execution_results]} ì„±ê³µë¥  ë†’ìŒ"
                )

        return {
            "workflow_pattern": None,  # ê¸°ë³¸ ëª¨ë“œëŠ” ê³ ì • ì›Œí¬í”Œë¡œìš° ì—†ìŒ
            "tools_used": execution_results,
            "confidence_score": intent_analysis.get("confidence", 0.7),
            "optimizations": [f"ììœ¨ ì„ íƒ: {len(refined_tools)}ê°œ ë„êµ¬ í™œìš©"],
            "lessons_learned": lessons_learned,
        }

    async def _plan_new_workflow(
        self,
        message: str,
        memories: Dict[MemoryType, List],
        user_preferences: Dict,
        context: Dict[str, Any],
    ) -> WorkflowPattern:
        """ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ê³„íš"""

        # AIë¥¼ í†µí•œ ì›Œí¬í”Œë¡œìš° ê³„íš ìƒì„±
        system_prompt = """
        ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ Step-Action-Tool ì›Œí¬í”Œë¡œìš°ë¥¼ ê³„íší•˜ì„¸ìš”.
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
        - SEARCH_DB: ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
        - GENERATE_MSG: ë©”ì‹œì§€ ìƒì„±
        - SEND_SLACK: Slack ì•Œë¦¼ ì „ì†¡
        - EMERGENCY_MAIL: ë¹„ìƒ ë©”ì¼ ë°ì´í„° ìƒì„±
        - SEND_EMAIL: ì´ë©”ì¼ ì „ì†¡
        
        3-5ë‹¨ê³„ì˜ ë…¼ë¦¬ì  ìˆœì„œë¡œ ê³„íší•˜ì„¸ìš”.
        """

        user_prompt = f"""
        ìš”ì²­: {message}
        ì»¨í…ìŠ¤íŠ¸: {context}
        ì‚¬ìš©ì ì„ í˜¸ë„: {user_preferences}
        
        JSON í˜•íƒœë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ê³„íší•˜ì„¸ìš”:
        {{
            "pattern_name": "ì›Œí¬í”Œë¡œìš° ì´ë¦„",
            "steps": [
                {{"step_id": 1, "step_name": "ë‹¨ê³„ëª…", "action": "ì•¡ì…˜", "tool_type": "SEARCH_DB", "parameters": {{}}}},
                ...
            ]
        }}
        """

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.1,
            )

            plan_json = json.loads(response.choices[0].message.content)

            # WorkflowPattern ê°ì²´ ìƒì„±
            steps = []
            for step_data in plan_json["steps"]:
                tool_calls = [
                    MCPToolCall(
                        tool_type=MCPToolType(step_data["tool_type"]),
                        parameters=step_data.get("parameters", {}),
                        context=context,
                    )
                ]

                step = WorkflowStep(
                    step_id=step_data["step_id"],
                    step_name=step_data["step_name"],
                    action=step_data["action"],
                    tool_calls=tool_calls,
                )
                steps.append(step)

            workflow_pattern = WorkflowPattern(
                pattern_id=f"wf_{int(time.time() * 1000)}",
                pattern_name=plan_json["pattern_name"],
                steps=steps,
                success_rate=0.0,  # ì´ˆê¸°ê°’
                avg_execution_time=0.0,
                usage_count=0,
                last_used=datetime.now(),
            )

            return workflow_pattern

        except Exception as e:
            # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ë°˜í™˜
            return self._create_default_workflow(message)

    async def _reuse_workflow_pattern(
        self, similar_procedure: Dict, context: Dict[str, Any]
    ) -> WorkflowPattern:
        """ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ì¬ì‚¬ìš©"""
        pattern_id = similar_procedure.get("pattern_id", "default")

        # ê¸°ë³¸ íŒ¨í„´ ìƒì„± (ì‹¤ì œë¡œëŠ” ì €ì¥ëœ íŒ¨í„´ì„ ë¶ˆëŸ¬ì™€ì•¼ í•¨)
        return self._create_default_workflow("ì¬ì‚¬ìš© ì›Œí¬í”Œë¡œìš°")

    def _create_default_workflow(self, message: str) -> WorkflowPattern:
        """ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        steps = [
            WorkflowStep(
                step_id=1,
                step_name="ë°ì´í„° ìˆ˜ì§‘",
                action="ì •ë³´ ì¡°íšŒ",
                tool_calls=[
                    MCPToolCall(
                        tool_type=MCPToolType.SEARCH_DB,
                        parameters={"query": message},
                        context={},
                    )
                ],
            ),
            WorkflowStep(
                step_id=2,
                step_name="ì‘ë‹µ ìƒì„±",
                action="ë©”ì‹œì§€ ì‘ì„±",
                tool_calls=[
                    MCPToolCall(
                        tool_type=MCPToolType.GENERATE_MSG,
                        parameters={"content": "ì¡°íšŒ ê²°ê³¼", "style": "professional"},
                        context={},
                    )
                ],
            ),
            WorkflowStep(
                step_id=3,
                step_name="ê²°ê³¼ ì „ë‹¬",
                action="ì•Œë¦¼ ë°œì†¡",
                tool_calls=[
                    MCPToolCall(
                        tool_type=MCPToolType.SEND_SLACK,
                        parameters={"message": "ê²°ê³¼ ë©”ì‹œì§€", "channel": "#general"},
                        context={},
                    )
                ],
            ),
        ]

        return WorkflowPattern(
            pattern_id=f"default_wf_{int(time.time())}",
            pattern_name="ê¸°ë³¸ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°",
            steps=steps,
            success_rate=0.8,
            avg_execution_time=5.0,
            usage_count=1,
            last_used=datetime.now(),
        )

    async def _execute_workflow(self, workflow_pattern: WorkflowPattern) -> List:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        results = []

        for step in workflow_pattern.steps:
            step.status = "running"
            step_start_time = time.time()

            # ë‹¨ê³„ë³„ ë„êµ¬ ì‹¤í–‰
            step_results = await self.mcp_service.execute_workflow(step.tool_calls)

            step.execution_time = time.time() - step_start_time
            step.result = step_results

            if all(r.success for r in step_results):
                step.status = "completed"
            else:
                step.status = "failed"
                break  # ì‹¤íŒ¨ ì‹œ ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨

            results.extend(step_results)

        return results

    async def _analyze_user_intent(
        self, message: str, memories: Dict[MemoryType, List], user_preferences: Dict
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""

        # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        memory_context = ""
        for memory_type, memory_list in memories.items():
            if memory_list:
                memory_context += (
                    f"\n{memory_type}: {memory_list[0].get('content', '')[:100]}"
                )

        system_prompt = """
        ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë„ì™€ í•„ìš”í•œ ë„êµ¬ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
        ë¶„ì„ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        """

        user_prompt = f"""
        ë©”ì‹œì§€: {message}
        ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸: {memory_context}
        ì‚¬ìš©ì ì„ í˜¸ë„: {user_preferences}
        
        ë‹¤ìŒ í˜•íƒœë¡œ ë¶„ì„í•˜ì„¸ìš”:
        {{
            "primary_intent": "ì£¼ìš” ì˜ë„",
            "urgency": "low|medium|high",
            "domain": "ë„ë©”ì¸ ì˜ì—­",
            "required_tools": ["í•„ìš”í•œ ë„êµ¬ ëª©ë¡"],
            "confidence": 0.8
        }}
        """

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.1,
            )

            return json.loads(response.choices[0].message.content)

        except Exception as e:
            # ê¸°ë³¸ ë¶„ì„ ë°˜í™˜
            return {
                "primary_intent": "ì¼ë°˜ ë¬¸ì˜",
                "urgency": "medium",
                "domain": "general",
                "required_tools": ["SEARCH_DB", "GENERATE_MSG"],
                "confidence": 0.5,
            }

    async def _refine_tools_from_episodes(
        self, suggested_tools: List[MCPToolType], episodes: List[Dict]
    ) -> List[MCPToolType]:
        """ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë„êµ¬ ì„ íƒ ê°œì„ """
        refined_tools = suggested_tools.copy()

        # ê³¼ê±° ì„±ê³µ ê²½í—˜ì—ì„œ íš¨ê³¼ì ì´ì—ˆë˜ ë„êµ¬ ìš°ì„ ìˆœìœ„ ì¡°ì •
        for episode in episodes:
            if "ì„±ê³µ" in episode.get("content", ""):
                # ì„±ê³µí•œ ì—í”¼ì†Œë“œì—ì„œ ì–¸ê¸‰ëœ ë„êµ¬ë“¤ì˜ ìš°ì„ ìˆœìœ„ ì¦ê°€
                # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ë¶„ì„ í•„ìš”
                pass

        return refined_tools

    def _generate_tool_parameters(
        self, tool_type: MCPToolType, message: str, intent_analysis: Dict
    ) -> Dict[str, Any]:
        """ë„êµ¬ë³„ íŒŒë¼ë¯¸í„° ìƒì„±"""

        if tool_type == MCPToolType.SEARCH_DB:
            return {
                "query": message[:100],  # ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ
                "table": "main_data",
                "filters": {},
            }

        elif tool_type == MCPToolType.GENERATE_MSG:
            style = "professional"
            if intent_analysis.get("urgency") == "high":
                style = "urgent"
            return {"content": message, "style": style, "length": "medium"}

        elif tool_type == MCPToolType.SEND_SLACK:
            return {"message": f"ì•Œë¦¼: {message}", "channel": "#general"}

        elif tool_type == MCPToolType.EMERGENCY_MAIL:
            return {
                "type": "general",
                "severity": intent_analysis.get("urgency", "medium"),
                "description": message,
            }

        else:
            return {}

    async def _generate_response(
        self, message: str, workflow_result: Dict, user_preferences: Dict
    ) -> str:
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""

        # ì‚¬ìš©ì ì„ í˜¸ ìŠ¤íƒ€ì¼ ì ìš©
        style = user_preferences.get("message_style", "professional")

        tools_used = [r.tool_type for r in workflow_result["tools_used"] if r.success]
        success_count = sum(1 for r in workflow_result["tools_used"] if r.success)

        if success_count == len(workflow_result["tools_used"]):
            base_response = f"ìš”ì²­ì„ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ëœ ë„êµ¬: {', '.join(map(str, tools_used))}"
        else:
            base_response = f"ìš”ì²­ì„ ë¶€ë¶„ì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ì„±ê³µí•œ ë„êµ¬: {success_count}/{len(workflow_result['tools_used'])}"

        # ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ ì‘ë‹µ ì¡°ì •
        if style == "casual":
            response = f"ì•ˆë…•í•˜ì„¸ìš”! {base_response} ğŸ˜Š"
        elif style == "technical":
            response = f"[ì²˜ë¦¬ ì™„ë£Œ] {base_response}\nì‹¤í–‰ ì‹œê°„: {workflow_result.get('processing_time', 0):.2f}ì´ˆ"
        elif style == "concise":
            response = base_response
        else:  # professional
            response = f"ì•ˆë…•í•˜ì„¸ìš”,\n\n{base_response}\n\nê°ì‚¬í•©ë‹ˆë‹¤."

        return response

    def _extract_lessons_from_execution(self, execution_results: List) -> List[str]:
        """ì‹¤í–‰ ê²°ê³¼ì—ì„œ êµí›ˆ ì¶”ì¶œ"""
        lessons = []

        success_count = sum(1 for r in execution_results if r.success)
        total_time = sum(r.execution_time for r in execution_results)

        if success_count == len(execution_results):
            lessons.append("ëª¨ë“  ë„êµ¬ ì‹¤í–‰ ì„±ê³µ")

        if total_time > 10.0:
            lessons.append("ì‹¤í–‰ ì‹œê°„ ìµœì í™” í•„ìš”")

        # ì‹¤íŒ¨í•œ ë„êµ¬ê°€ ìˆëŠ” ê²½ìš°
        failed_tools = [r.tool_type for r in execution_results if not r.success]
        if failed_tools:
            lessons.append(f"ì‹¤íŒ¨ ë„êµ¬: {failed_tools} - ëŒ€ì•ˆ ë„êµ¬ ê²€í†  í•„ìš”")

        return lessons
