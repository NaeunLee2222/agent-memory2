import streamlit as st
import requests
import time
import json
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
from datetime import datetime, timedelta
import asyncio
from streamlit_option_menu import option_menu
from streamlit_autorefresh import st_autorefresh

# ì„¤ì •
BACKEND_URL = "http://backend:8100"

st.set_page_config(
    page_title="Enhanced Agentic AI PoC",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "session_id" not in st.session_state:
    st.session_state.session_id = f"session_{int(time.time())}"
if "user_id" not in st.session_state:
    st.session_state.user_id = "demo_user"
if "performance_data" not in st.session_state:
    st.session_state.performance_data = []
if "feedback_history" not in st.session_state:
    st.session_state.feedback_history = []

def call_backend(endpoint, method="GET", data=None):
    """ë°±ì—”ë“œ API í˜¸ì¶œ"""
    try:
        url = f"{BACKEND_URL}{endpoint}"
        if method == "GET":
            response = requests.get(url, timeout=30)
        else:
            response = requests.post(url, json=data, timeout=30)
        
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"ë°±ì—”ë“œ ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

def send_chat_message(message, mode):
    """ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡"""
    data = {
        "message": message,
        "user_id": st.session_state.user_id,
        "session_id": st.session_state.session_id,
        "mode": mode,
        "context": {}
    }
    
    with st.spinner("ğŸ¤– AIê°€ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
        response = call_backend("/chat", method="POST", data=data)
    
    if response:
        # ì„±ëŠ¥ ë°ì´í„° ì €ì¥
        st.session_state.performance_data.append({
            "timestamp": datetime.now(),
            "processing_time": response.get("processing_time", 0),
            "tools_used": len(response.get("tools_used", [])),
            "confidence_score": response.get("confidence_score", 0),
            "mode": mode,
            "memory_types": len([k for k, v in response.get("memory_used", {}).items() if v])
        })
        
        return response
    return None

def send_feedback(feedback_type, content, rating=None):
    """í”¼ë“œë°± ì „ì†¡"""
    data = {
        "session_id": st.session_state.session_id,
        "user_id": st.session_state.user_id,
        "feedback_type": feedback_type,
        "content": content,
        "rating": rating
    }
    
    start_time = time.time()
    response = call_backend("/feedback", method="POST", data=data)
    end_time = time.time()
    
    if response:
        feedback_record = {
            "timestamp": datetime.now(),
            "type": feedback_type,
            "content": content,
            "response_time": end_time - start_time,
            "optimizations": response.get("optimizations", []),
            "applied": response.get("applied", False)
        }
        st.session_state.feedback_history.append(feedback_record)
        
        # 5ì´ˆ ì´ë‚´ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í‘œì‹œ
        if end_time - start_time < 5.0:
            st.success(f"âœ… í”¼ë“œë°±ì´ {end_time - start_time:.2f}ì´ˆ ë§Œì— ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning(f"âš ï¸ í”¼ë“œë°± ì²˜ë¦¬ê°€ {end_time - start_time:.2f}ì´ˆ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤ (ëª©í‘œ: 5ì´ˆ ì´ë‚´)")
        
        if response.get("optimizations"):
            st.write("**ì ìš©ëœ ìµœì í™”:**")
            for opt in response["optimizations"]:
                st.write(f"- {opt}")
    
    return response

# === ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ===
st.title("ğŸ¤– Enhanced Agentic AI PoC")
st.markdown("**MCP ë„êµ¬ ê¸°ë°˜ ì§€ëŠ¥í˜• ë©”ëª¨ë¦¬ì™€ 5ì´ˆ ì´ë‚´ í”¼ë“œë°± ë£¨í”„**")

# ì‚¬ì´ë“œë°” ë©”ë‰´
with st.sidebar:
    selected = option_menu(
        "ë©”ì¸ ë©”ë‰´",
        ["ğŸ’¬ ì±„íŒ…", "ğŸ§  ë©”ëª¨ë¦¬ ë¶„ì„", "âš¡ í”¼ë“œë°± ì„¼í„°", "ğŸ“Š ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ", "ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ"],
        icons=['chat', 'brain', 'lightning', 'graph-up', 'gear'],
        menu_icon="robot",
        default_index=0,
    )
    
    st.markdown("---")
    
    # ì‚¬ìš©ì ì„¤ì •
    st.header("ğŸ‘¤ ì‚¬ìš©ì ì„¤ì •")
    st.session_state.user_id = st.text_input("ì‚¬ìš©ì ID", value=st.session_state.user_id)
    
    # ìƒˆ ì„¸ì…˜ ì‹œì‘
    if st.button("ğŸ”„ ìƒˆ ì„¸ì…˜ ì‹œì‘"):
        st.session_state.session_id = f"session_{int(time.time())}"
        st.session_state.messages = []
        st.success("ìƒˆ ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()

# === ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ===
if selected == "ğŸ’¬ ì±„íŒ…":
    st.header("ğŸ’¬ ì§€ëŠ¥í˜• ì±„íŒ… ì¸í„°í˜ì´ìŠ¤")
    
    # ëª¨ë“œ ì„ íƒ
    col1, col2 = st.columns(2)
    with col1:
        mode = st.radio("ì‹¤í–‰ ëª¨ë“œ", ["flow", "basic"], 
                       help="Flow: êµ¬ì¡°í™”ëœ Step-Action-Tool, Basic: ììœ¨ì  ë„êµ¬ ì„ íƒ")
    with col2:
        st.write("**í˜„ì¬ ì„¸ì…˜:**", st.session_state.session_id[-8:])
        st.write("**ì²˜ë¦¬ëœ ë©”ì‹œì§€:**", len(st.session_state.messages) // 2)
    
    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ë²„íŠ¼ë“¤
    st.subheader("ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
    test_col1, test_col2, test_col3 = st.columns(3)
    
    with test_col1:
        if st.button("ğŸ“Š ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸"):
            test_message = "ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  Slackìœ¼ë¡œ ì•Œë¦¼í•´ì£¼ì„¸ìš”"
            st.session_state.test_message = test_message
    
    with test_col2:
        if st.button("ğŸš¨ ë¹„ìƒ ì•Œë¦¼ í…ŒìŠ¤íŠ¸"):
            test_message = "SHE ë¹„ìƒ ìƒí™©ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê¸´ê¸‰ ì•Œë¦¼ì„ ë³´ë‚´ì£¼ì„¸ìš”"
            st.session_state.test_message = test_message
    
    with test_col3:
        if st.button("ğŸ”„ ì ˆì°¨ í•™ìŠµ í…ŒìŠ¤íŠ¸"):
            test_message = "ì£¼ê°„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³  ê´€ë ¨ íŒ€ì— ì „ì†¡í•´ì£¼ì„¸ìš”"
            st.session_state.test_message = test_message
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                if message["role"] == "assistant" and "metadata" in message:
                    with st.expander("ğŸ“Š ì‹¤í–‰ ìƒì„¸ ì •ë³´"):
                        metadata = message["metadata"]
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{metadata.get('processing_time', 0):.2f}ì´ˆ")
                        with col2:
                            st.metric("ì‚¬ìš© ë„êµ¬", f"{len(metadata.get('tools_used', []))}ê°œ")
                        with col3:
                            st.metric("ì‹ ë¢°ë„", f"{metadata.get('confidence_score', 0):.1%}")
                        
                        if metadata.get("workflow_executed"):
                            st.write("**ì‹¤í–‰ëœ ì›Œí¬í”Œë¡œìš°:**", metadata["workflow_executed"].get("pattern_name", "N/A"))
                        
                        if metadata.get("memory_used"):
                            st.write("**í™œìš©ëœ ë©”ëª¨ë¦¬:**")
                            for memory_type, items in metadata["memory_used"].items():
                                if items:
                                    st.write(f"- {memory_type}: {len(items)}ê°œ í•­ëª©")
                        
                        if metadata.get("optimization_applied"):
                            st.write("**ì ìš©ëœ ìµœì í™”:**")
                            for opt in metadata["optimization_applied"]:
                                st.write(f"- {opt}")
    
    # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ìë™ ì…ë ¥
    default_message = ""
    if hasattr(st.session_state, 'test_message'):
        default_message = st.session_state.test_message
        delattr(st.session_state, 'test_message')
    
    # ì±„íŒ… ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", value=default_message):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ì²˜ë¦¬
        response = send_chat_message(prompt, mode)
        
        if response:
            # AI ì‘ë‹µ ì¶”ê°€
            assistant_message = {
                "role": "assistant",
                "content": response["response"],
                "metadata": response
            }
            st.session_state.messages.append(assistant_message)
            
            with st.chat_message("assistant"):
                st.markdown(response["response"])
                
                with st.expander("ğŸ“Š ì‹¤í–‰ ìƒì„¸ ì •ë³´"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì²˜ë¦¬ ì‹œê°„", f"{response.get('processing_time', 0):.2f}ì´ˆ")
                    with col2:
                        st.metric("ì‚¬ìš© ë„êµ¬", f"{len(response.get('tools_used', []))}ê°œ")
                    with col3:
                        st.metric("ì‹ ë¢°ë„", f"{response.get('confidence_score', 0):.1%}")
    
    # ì¦‰ì‹œ í”¼ë“œë°± ì„¹ì…˜
    with st.expander("âš¡ ì¦‰ì‹œ í”¼ë“œë°± (5ì´ˆ ì´ë‚´ ëª©í‘œ)", expanded=False):
        feedback_col1, feedback_col2 = st.columns(2)
        
        with feedback_col1:
            st.write("**ìŠ¤íƒ€ì¼ í”¼ë“œë°±**")
            if st.button("ğŸ­ ë” ì¹œê·¼í•˜ê²Œ"):
                send_feedback("style_preference", "ë” ì¹œê·¼í•˜ê³  ìºì£¼ì–¼í•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•´ì£¼ì„¸ìš”")
            if st.button("ğŸ’¼ ë” ê³µì‹ì ìœ¼ë¡œ"):
                send_feedback("style_preference", "ë” ê³µì‹ì ì´ê³  ë¹„ì¦ˆë‹ˆìŠ¤ í†¤ìœ¼ë¡œ ëŒ€í™”í•´ì£¼ì„¸ìš”")
            if st.button("ğŸ”¬ ë” ê¸°ìˆ ì ìœ¼ë¡œ"):
                send_feedback("style_preference", "ë” ê¸°ìˆ ì ì´ê³  ì „ë¬¸ì ì¸ ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”")
        
        with feedback_col2:
            st.write("**ë‚´ìš© í”¼ë“œë°±**")
            if st.button("ğŸ“ ë” ìì„¸íˆ"):
                send_feedback("response_quality", "ì‘ë‹µì´ ë„ˆë¬´ ê°„ë‹¨í•´ìš”. ë” ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•´ìš”", rating=2.0)
            if st.button("ğŸ“‹ ë” ê°„ëµí•˜ê²Œ"):
                send_feedback("response_quality", "ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ì–´ìš”. ë” ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”", rating=2.5)
            if st.button("ğŸš€ ì†ë„ ìš°ì„ "):
                send_feedback("workflow_efficiency", "ì •í™•ë„ë³´ë‹¤ ë¹ ë¥¸ ì‘ë‹µì´ ë” ì¤‘ìš”í•´ìš”")

# === ë©”ëª¨ë¦¬ ë¶„ì„ ===
elif selected == "ğŸ§  ë©”ëª¨ë¦¬ ë¶„ì„":
    st.header("ğŸ§  ì§€ëŠ¥í˜• ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë¶„ì„")
    
    # ì‹¤ì‹œê°„ ìƒˆë¡œê³ ì¹¨
    st_autorefresh(interval=10000, key="memory_refresh")  # 10ì´ˆë§ˆë‹¤ ìƒˆë¡œê³ ì¹¨
    
    # ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ
    memory_stats = call_backend("/memory/stats")
    
    if memory_stats:
        st.subheader("ğŸ“Š ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ í˜„í™©")
        
        # ë©”íŠ¸ë¦­ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            working_count = memory_stats.get("working_memory", {}).get("total_keys", 0)
            st.metric("ì‘ì—… ë©”ëª¨ë¦¬", f"{working_count}ê°œ", help="í˜„ì¬ í™œì„± ì„¸ì…˜ì˜ ì„ì‹œ ë©”ëª¨ë¦¬")
        
        with col2:
            episodic_count = memory_stats.get("episodic_memory", {}).get("episodes_count", 0)
            st.metric("ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬", f"{episodic_count}ê°œ", help="ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ê¸°ë¡")
        
        with col3:
            semantic_nodes = memory_stats.get("semantic_memory", {}).get("nodes_count", 0)
            st.metric("ì‹œë§¨í‹± ë©”ëª¨ë¦¬", f"{semantic_nodes}ê°œ", help="ë„ë©”ì¸ ì§€ì‹ ë…¸ë“œ")
        
        with col4:
            procedures_count = memory_stats.get("episodic_memory", {}).get("procedures_count", 0)
            st.metric("ì ˆì°¨ ë©”ëª¨ë¦¬", f"{procedures_count}ê°œ", help="í•™ìŠµëœ ì›Œí¬í”Œë¡œìš° íŒ¨í„´")
        
        # ì„±ëŠ¥ ì§€í‘œ
        if "performance" in memory_stats:
            st.subheader("âš¡ ë©”ëª¨ë¦¬ ì„±ëŠ¥ ì§€í‘œ")
            perf = memory_stats["performance"]
            
            perf_col1, perf_col2 = st.columns(2)
            with perf_col1:
                avg_time = perf.get("avg_retrieval_time", 0)
                color = "green" if avg_time < 0.2 else "orange" if avg_time < 0.5 else "red"
                st.metric(
                    "í‰ê·  ê²€ìƒ‰ ì‹œê°„", 
                    f"{avg_time:.3f}ì´ˆ", 
                    help="ëª©í‘œ: 0.2ì´ˆ ì´í•˜",
                    delta=f"ëª©í‘œ ëŒ€ë¹„ {(avg_time - 0.2):.3f}ì´ˆ" if avg_time > 0.2 else "ëª©í‘œ ë‹¬ì„±!"
                )
            
            with perf_col2:
                total_ops = perf.get("total_operations", 0)
                st.metric("ì´ ì‘ì—… ìˆ˜", f"{total_ops:,}íšŒ")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì‹œê°í™”
        st.subheader("ğŸ“ˆ ë©”ëª¨ë¦¬ ì‚¬ìš© ë¶„í¬")
        
        memory_data = {
            "ë©”ëª¨ë¦¬ ìœ í˜•": ["ì‘ì—… ë©”ëª¨ë¦¬", "ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬", "ì‹œë§¨í‹± ë©”ëª¨ë¦¬", "ì ˆì°¨ ë©”ëª¨ë¦¬"],
            "í•­ëª© ìˆ˜": [
                working_count,
                episodic_count, 
                semantic_nodes,
                procedures_count
            ]
        }
        
        df_memory = pd.DataFrame(memory_data)
        fig_pie = px.pie(df_memory, values="í•­ëª© ìˆ˜", names="ë©”ëª¨ë¦¬ ìœ í˜•", 
                        title="ë©”ëª¨ë¦¬ ìœ í˜•ë³„ ë¶„í¬")
        st.plotly_chart(fig_pie, use_container_width=True)
        
        # Redis ìƒì„¸ ì •ë³´
        if "working_memory" in memory_stats:
            st.subheader("ğŸ’¾ Redis ì‘ì—… ë©”ëª¨ë¦¬ ìƒì„¸")
            redis_info = memory_stats["working_memory"]
            
            detail_col1, detail_col2 = st.columns(2)
            with detail_col1:
                st.write(f"**ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:** {redis_info.get('memory_usage', 'N/A')}")
            with detail_col2:
                st.write(f"**ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸:** {redis_info.get('connected_clients', 0)}ê°œ")
    
    # ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì„¹ì…˜
    st.subheader("ğŸ§ª ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    test_col1, test_col2 = st.columns(2)
    
    with test_col1:
        st.write("**ì ˆì°¨ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸**")
        if st.button("ğŸ“‹ ì›Œí¬í”Œë¡œìš° í•™ìŠµ í…ŒìŠ¤íŠ¸"):
            # ë™ì¼í•œ ì‘ì—…ì„ 3ë²ˆ ìˆ˜í–‰í•˜ì—¬ ì ˆì°¨ í•™ìŠµ í™•ì¸
            test_message = "ë°ì´í„° ì¡°íšŒ â†’ ë©”ì‹œì§€ ìƒì„± â†’ Slack ì „ì†¡ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"
            response = send_chat_message(test_message, "flow")
            if response:
                st.success("ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ! 3íšŒ ë°˜ë³µ í›„ ìë™ í•™ìŠµì„ í™•ì¸í•´ë³´ì„¸ìš”.")
    
    with test_col2:
        st.write("**ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸**")
        if st.button("ğŸ¯ ê°œì¸í™” í•™ìŠµ í…ŒìŠ¤íŠ¸"):
            test_message = "ì œ ì„ í˜¸ë„ë¥¼ ê¸°ì–µí•´ì£¼ì„¸ìš”: ê°„ê²°í•œ ë©”ì‹œì§€, ê¸°ìˆ ì  ì„¤ëª… ì„ í˜¸"
            response = send_chat_message(test_message, "basic")
            if response:
                st.success("ì„ í˜¸ë„ ì €ì¥ ì™„ë£Œ! ë‹¤ìŒ ëŒ€í™”ì—ì„œ ê°œì¸í™” íš¨ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")

# === í”¼ë“œë°± ì„¼í„° ===
elif selected == "âš¡ í”¼ë“œë°± ì„¼í„°":
    st.header("âš¡ ì‹¤ì‹œê°„ í”¼ë“œë°± ì„¼í„°")
    st.markdown("**ëª©í‘œ: 5ì´ˆ ì´ë‚´ í”¼ë“œë°± ë°˜ì˜**")
    
    # í”¼ë“œë°± ì´ë ¥ í‘œì‹œ
    if st.session_state.feedback_history:
        st.subheader("ğŸ“Š í”¼ë“œë°± ì²˜ë¦¬ ì„±ëŠ¥")
        
        df_feedback = pd.DataFrame(st.session_state.feedback_history)
        
        # 5ì´ˆ ì´ë‚´ ë‹¬ì„±ë¥  ê³„ì‚°
        within_5s = len(df_feedback[df_feedback["response_time"] < 5.0])
        total_feedback = len(df_feedback)
        success_rate = (within_5s / total_feedback * 100) if total_feedback > 0 else 0
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("5ì´ˆ ì´ë‚´ ì²˜ë¦¬ìœ¨", f"{success_rate:.1f}%", 
                     help="ëª©í‘œ: 95% ì´ìƒ")
        with col2:
            avg_time = df_feedback["response_time"].mean()
            st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{avg_time:.2f}ì´ˆ")
        with col3:
            st.metric("ì´ í”¼ë“œë°±", f"{total_feedback}ê±´")
        
        # í”¼ë“œë°± ì²˜ë¦¬ ì‹œê°„ ë¶„í¬ ì°¨íŠ¸
        fig_hist = px.histogram(df_feedback, x="response_time", 
                               title="í”¼ë“œë°± ì²˜ë¦¬ ì‹œê°„ ë¶„í¬",
                               labels={"response_time": "ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)", "count": "ë¹ˆë„"})
        fig_hist.add_vline(x=5.0, line_dash="dash", line_color="red", 
                          annotation_text="ëª©í‘œ: 5ì´ˆ")
        st.plotly_chart(fig_hist, use_container_width=True)
        
        # ìµœê·¼ í”¼ë“œë°± ì´ë ¥
        st.subheader("ğŸ“ ìµœê·¼ í”¼ë“œë°± ì´ë ¥")
        recent_feedback = df_feedback.tail(10).sort_values("timestamp", ascending=False)
        
        for _, feedback in recent_feedback.iterrows():
            with st.expander(f"ğŸ•’ {feedback['timestamp'].strftime('%H:%M:%S')} - {feedback['type']}"):
                st.write(f"**ë‚´ìš©:** {feedback['content']}")
                st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {feedback['response_time']:.2f}ì´ˆ")
                st.write(f"**ì ìš© ì—¬ë¶€:** {'âœ… ì ìš©ë¨' if feedback['applied'] else 'âŒ ë¯¸ì ìš©'}")
                
                if feedback['optimizations']:
                    st.write("**ì ìš©ëœ ìµœì í™”:**")
                    for opt in feedback['optimizations']:
                        st.write(f"- {opt}")
    
    # ê³ ê¸‰ í”¼ë“œë°± ì…ë ¥
    st.subheader("ğŸ’¬ ìƒì„¸ í”¼ë“œë°± ì…ë ¥")
    
    feedback_type = st.selectbox("í”¼ë“œë°± ìœ í˜•", [
        "style_preference", "response_quality", "tool_performance", 
        "workflow_efficiency", "user_experience"
    ])
    
    feedback_content = st.text_area("í”¼ë“œë°± ë‚´ìš©", 
                                   placeholder="êµ¬ì²´ì ì¸ ê°œì„  ì‚¬í•­ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”...")
    
    rating = st.slider("ë§Œì¡±ë„ í‰ê°€", 1.0, 5.0, 3.0, 0.5)
    
    if st.button("ğŸš€ í”¼ë“œë°± ì œì¶œ (5ì´ˆ ì´ë‚´ ëª©í‘œ)"):
        if feedback_content:
            send_feedback(feedback_type, feedback_content, rating)
        else:
            st.warning("í”¼ë“œë°± ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # í¬ë¡œìŠ¤ ì—ì´ì „íŠ¸ í•™ìŠµ í…ŒìŠ¤íŠ¸
    st.subheader("ğŸ¤ í¬ë¡œìŠ¤ ì—ì´ì „íŠ¸ í•™ìŠµ í…ŒìŠ¤íŠ¸")
    st.write("ë‹¤ë¥¸ ì„¸ì…˜ì—ì„œ í•™ìŠµí•œ ì„ í˜¸ë„ê°€ í˜„ì¬ ì„¸ì…˜ì— ì ìš©ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    
    if st.button("ğŸ”„ ë‹¤ë¥¸ ì„¸ì…˜ ì„ í˜¸ë„ ë™ê¸°í™”"):
        # ë‹¤ë¥¸ ì‚¬ìš©ì IDë¡œ ì„ í˜¸ë„ ì„¤ì • í›„ í˜„ì¬ ì„¸ì…˜ì— ì ìš© í…ŒìŠ¤íŠ¸
        sync_response = send_feedback("preference_sync", "ë‹¤ë¥¸ ì—ì´ì „íŠ¸ í•™ìŠµ ë‚´ìš©ì„ í˜„ì¬ ì„¸ì…˜ì— ë™ê¸°í™”")
        if sync_response:
            st.success("í¬ë¡œìŠ¤ ì—ì´ì „íŠ¸ í•™ìŠµ ë™ê¸°í™” ì™„ë£Œ!")

# === ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ===
elif selected == "ğŸ“Š ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ")
    
    # ìë™ ìƒˆë¡œê³ ì¹¨
    st_autorefresh(interval=5000, key="dashboard_refresh")  # 5ì´ˆë§ˆë‹¤ ìƒˆë¡œê³ ì¹¨
    
    if st.session_state.performance_data:
        df_perf = pd.DataFrame(st.session_state.performance_data)
        
        # ìµœê·¼ 30ë¶„ ë°ì´í„°ë§Œ í‘œì‹œ
        current_time = datetime.now()
        df_recent = df_perf[df_perf["timestamp"] > (current_time - timedelta(minutes=30))]
        
        if not df_recent.empty:
            # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­
            st.subheader("âš¡ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                avg_processing = df_recent["processing_time"].mean()
                st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{avg_processing:.2f}ì´ˆ",
                         delta=f"{avg_processing - df_recent['processing_time'].iloc[0]:.2f}ì´ˆ")
            
            with col2:
                avg_confidence = df_recent["confidence_score"].mean()
                st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.1%}")
            
            with col3:
                avg_tools = df_recent["tools_used"].mean()
                st.metric("í‰ê·  ë„êµ¬ ì‚¬ìš©", f"{avg_tools:.1f}ê°œ")
            
            with col4:
                avg_memory = df_recent["memory_types"].mean()
                st.metric("í‰ê·  ë©”ëª¨ë¦¬ í™œìš©", f"{avg_memory:.1f}ê°œ ìœ í˜•")
            
            # ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥ ì¶”ì´
            st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥ ì¶”ì´")
            
            # ì²˜ë¦¬ ì‹œê°„ ì¶”ì´
            fig_time = px.line(df_recent, x="timestamp", y="processing_time", 
                              color="mode", title="ì²˜ë¦¬ ì‹œê°„ ì¶”ì´")
            fig_time.add_hline(y=3.0, line_dash="dash", line_color="orange", 
                              annotation_text="ëª©í‘œ: 3ì´ˆ ì´ë‚´")
            st.plotly_chart(fig_time, use_container_width=True)
            
            # ëª¨ë“œë³„ ì„±ëŠ¥ ë¹„êµ
            st.subheader("ğŸ”„ ëª¨ë“œë³„ ì„±ëŠ¥ ë¹„êµ")
            
            mode_comparison = df_recent.groupby("mode").agg({
                "processing_time": ["mean", "std"],
                "confidence_score": "mean",
                "tools_used": "mean"
            }).round(3)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ëª¨ë“œë³„ ì²˜ë¦¬ ì‹œê°„ ë°•ìŠ¤í”Œë¡¯
                fig_box = px.box(df_recent, x="mode", y="processing_time", 
                                title="ëª¨ë“œë³„ ì²˜ë¦¬ ì‹œê°„ ë¶„í¬")
                st.plotly_chart(fig_box, use_container_width=True)
            
            with col2:
                # ëª¨ë“œë³„ ì‹ ë¢°ë„ ë¹„êµ
                fig_conf = px.bar(df_recent.groupby("mode")["confidence_score"].mean().reset_index(), 
                                 x="mode", y="confidence_score", 
                                 title="ëª¨ë“œë³„ í‰ê·  ì‹ ë¢°ë„")
                st.plotly_chart(fig_conf, use_container_width=True)
            
            # ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± í˜„í™©
            st.subheader("ğŸ¯ ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± í˜„í™©")
            
            target_col1, target_col2, target_col3 = st.columns(3)
            
            with target_col1:
                # ì²˜ë¦¬ ì‹œê°„ ëª©í‘œ (3ì´ˆ ì´ë‚´)
                under_3s = len(df_recent[df_recent["processing_time"] < 3.0])
                time_success_rate = (under_3s / len(df_recent) * 100)
                
                fig_gauge_time = go.Figure(go.Indicator(
                    mode = "gauge+number+delta",
                    value = time_success_rate,
                    domain = {'x': [0, 1], 'y': [0, 1]},
                    title = {'text': "ì²˜ë¦¬ ì‹œê°„ ëª©í‘œ ë‹¬ì„±ë¥  (%)"},
                    delta = {'reference': 90},
                    gauge = {'axis': {'range': [None, 100]},
                             'bar': {'color': "darkblue"},
                             'steps': [    def _calculate_expected_improvements(self, optimizations: List[str]) -> Dict[str, float]:
        """ìµœì í™”ë¡œ ì¸í•œ ì˜ˆìƒ ê°œì„  íš¨ê³¼ ê³„ì‚°"""
        improvements = {}
        
        for optimization in optimizations:
            if "ì†ë„" in optimization or "ìºì‹±" in optimization:
                improvements["response_time_improvement"] = improvements.get("response_time_improvement", 0) + 0.25
                
            elif "ì•ˆì •ì„±" in optimization or "ì‹ ë¢°ì„±" in optimization:
                improvements["reliability_improvement"] = improvements.get("reliability_improvement", 0) + 0.15
                
            elif "ì •í™•ë„" in optimization or "í’ˆì§ˆ" in optimization:
                improvements["accuracy_improvement"] = improvements.get("accuracy_improvement", 0) + 0.20
                
            elif "ë§Œì¡±ë„" in optimization or "ì‚¬ìš©ì" in optimization:
                improvements["user_satisfaction_improvement"] = improvements.get("user_satisfaction_improvement", 0) + 0.30
        
        return improvements
    
    async def get_optimization_history(self, tool_type: MCPToolType = None) -> Dict[str, Any]:
        """ìµœì í™” ì´ë ¥ ì¡°íšŒ"""
        if tool_type:
            return {
                str(tool_type): self.optimization_history.get(tool_type, [])
            }
        return {str(k): v for k, v in self.optimization_history.items()}
    
    async def get_user_preferences(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ"""
        # ë©”ëª¨ë¦¬ì—ì„œë„ ì¡°íšŒ (í¬ë¡œìŠ¤ ì—ì´ì „íŠ¸ í•™ìŠµìš©)
        preferences, _ = await self.memory_service.get_working_memory(f"preferences_{user_id}", "shared_preferences")
        
        # í˜„ì¬ ì„¸ì…˜ ì„ í˜¸ë„ì™€ ë³‘í•©
        current_preferences = self.user_preferences.get(user_id, {})
        
        return {**preferences.get("shared_preferences", {}), **current_preferences}
